{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a30327-2789-4dbf-9fdf-3ea10d1a43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289d6f0-6a52-4ea5-acbf-dde98812abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"512_DCGAN_LOSS\"\n",
    "\n",
    "if not os.path.exists(\"./results/{}\".format(experiment_name)):\n",
    "    os.makedirs(\"./results/{}\".format(experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9615ef5-e7b2-4f00-baa4-11dfacc30ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIV2KDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, lr_transform=None, hr_transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.lr_transform = lr_transform\n",
    "        self.hr_transform = hr_transform\n",
    "        self.lr_dir = os.path.join(root_dir, 'LR/X4')\n",
    "        self.hr_dir = os.path.join(root_dir, 'HR')\n",
    "        self.images = [f for f in os.listdir(self.hr_dir) if not f.startswith('.')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr_img_name = os.path.join(self.lr_dir, self.images[idx][:-4] + \"x4\" + self.images[idx][-4:])\n",
    "        hr_img_name = os.path.join(self.hr_dir, self.images[idx])\n",
    "        lr_image = Image.open(lr_img_name)\n",
    "        hr_image = Image.open(hr_img_name)\n",
    "        \n",
    "        if self.lr_transform:\n",
    "            lr_image = self.lr_transform(lr_image)\n",
    "        if self.hr_transform:     \n",
    "            hr_image = self.hr_transform(hr_image)\n",
    "\n",
    "        return lr_image, hr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66973704-632f-4ad7-8cb5-a9c0686a3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_transform = T.Compose([\n",
    "    T.Resize((128,128)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "hr_transform = T.Compose([\n",
    "    T.Resize((512,512)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "root_train = \"./datasets/train/\"\n",
    "root_val = \"./datasets/val/\"\n",
    "\n",
    "train_ds = DIV2KDataset(root_dir=root_train, hr_transform=hr_transform, lr_transform=lr_transform)\n",
    "val_ds = DIV2KDataset(root_dir=root_val, hr_transform=hr_transform, lr_transform=lr_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce2cc5-8c6b-4696-b7f3-c3166863b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers = 4, prefetch_factor = 13, pin_memory_device = 'cuda')\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers = 4, prefetch_factor = 13, pin_memory_device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c80d740-2a53-4909-a82d-3e918a52354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(lr, hr) = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139434bc-8eee-41e2-889e-1b55c974ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_to_plot = 2\n",
    "fig, axes = plt.subplots(num_samples_to_plot, 2, figsize=(10, 10))\n",
    "\n",
    "samples = [160, 170]\n",
    "for i, sample in enumerate(samples):\n",
    "    lr_image, hr_image = train_ds[sample]\n",
    "    lr_image = np.array(lr_image).transpose(1, 2, 0)  # Transpose LR image data\n",
    "    hr_image = np.array(hr_image).transpose(1, 2, 0)  # Transpose HR image data\n",
    "\n",
    "    axes[i, 0].imshow(lr_image)\n",
    "    axes[i, 0].set_title('LR Image')\n",
    "    axes[i, 1].imshow(hr_image)\n",
    "    axes[i, 1].set_title('HR Image')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2f5d9-ba3c-4d31-a589-13a66fedc482",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed76bec-7dde-460c-81b6-73df410b9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3, 64, \n",
    "            kernel_size=5, stride=2, padding=2\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            64, 128,\n",
    "            kernel_size=5, stride=2, padding=2\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            2097152, 1\n",
    "        )\n",
    "\n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = F.leaky_relu(out, negative_slope=0.3)\n",
    "        out = F.dropout(out, p=0.3)\n",
    "        out = self.conv2(out)\n",
    "        # print(out.shape)\n",
    "        out = F.leaky_relu(out, negative_slope=0.3)\n",
    "        out = F.dropout(out, p=0.3)\n",
    "        out = out.view(xb.shape[0], -1)\n",
    "        # print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b0a96b-82a2-4cc7-a1e3-98e51b76d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # self.conv  = nn.Upsample(size=(256, 64, 64), mode='bicubic')\n",
    "        self.conv1 = nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(\n",
    "            num_features=128\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(*[\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        ])\n",
    "        self.bn2 = nn.BatchNorm2d(\n",
    "            num_features=64\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(*[\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.bn1(out)\n",
    "        out = F.leaky_relu(out, negative_slope=0.3)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.leaky_relu(out, negative_slope=0.3)\n",
    "        out = self.conv3(out)\n",
    "        out = F.tanh(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc69b09-f739-4f77-a6cb-a0554ab04f2c",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c518c9-15b4-48d6-b3df-40090bede917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class VGGFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGFeatureExtractor, self).__init__()\n",
    "        vgg19 = models.vgg19(pretrained=True)\n",
    "        self.features = vgg19.features[:35].eval()  # Extract features till conv4_4\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "\n",
    "vgg = VGGFeatureExtractor().cuda()\n",
    "def g_criterion(image1, image2, vgg=vgg):\n",
    "    x, y = image1.cuda(), image2.cuda()\n",
    "    # Preprocess images\n",
    "    preprocess = T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        # T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    image1 = preprocess(image1).cuda()\n",
    "    image2 = preprocess(image2).cuda()\n",
    "\n",
    "    # features1 = vgg(image1)\n",
    "    # features2 = vgg(image2)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    # vgg_loss = criterion(features1, features2)\n",
    "    mse_loss = criterion(x, y)\n",
    "    loss  =  mse_loss\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939cf52b-6b4d-4ecb-a625-4233a7df2ea4",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da3b6e1-e0b3-413c-994d-d72b794812b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(G, D, train_dl, criterion, g_criterion, D_opt, G_opt, epochs, save_epochs = [1, 10, 30, 50], start_idx=0):\n",
    "    losses_generator = torch.Tensor([0 for _ in range(epochs)])\n",
    "    losses_discriminator = torch.Tensor([0 for _ in range(epochs)])\n",
    "\n",
    "    device = next(G.parameters()).device\n",
    "    \n",
    "    for epoch in range(start_idx, start_idx+epochs):\n",
    "        g_running = 0\n",
    "        d_running = 0\n",
    "        \n",
    "        for lr, hr in tqdm(train_dl, desc=f'Epoch {epoch+1}/{start_idx+epochs}', leave=True):\n",
    "            lr = lr.to(device)\n",
    "            hr = hr.to(device)\n",
    "            sr = G(lr)\n",
    "            labels_shape = (lr.shape[0], )\n",
    "\n",
    "            # Discriminator training\n",
    "            D_opt.zero_grad()\n",
    "            y_fake = torch.zeros(labels_shape, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "            y_real = torch.ones(labels_shape, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "            loss_d1 = criterion(D(sr), y_fake)\n",
    "            loss_d2 = criterion(D(hr), y_real)\n",
    "            \n",
    "            loss_discriminator = loss_d1 + loss_d2\n",
    "            d_running += loss_discriminator.item()\n",
    "            loss_discriminator.backward()\n",
    "            D_opt.step()\n",
    "    \n",
    "            # Generator Training\n",
    "            G_opt.zero_grad()\n",
    "            sr = G(lr)\n",
    "            y_real = torch.ones(labels_shape, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "            loss_g1 = criterion(\n",
    "                D(sr), y_real\n",
    "            )\n",
    "            loss_g2 = g_criterion(sr, hr)\n",
    "\n",
    "            loss_generator = 0.1*(loss_g1 + 0.01 * loss_g2)\n",
    "            g_running += loss_generator.item()\n",
    "            loss_generator.backward()\n",
    "            G_opt.step()\n",
    "            \n",
    "        g_running /= len(train_dl)\n",
    "        d_running /= (2*len(train_dl))\n",
    "        losses_generator[epoch - start_idx] = g_running\n",
    "        losses_discriminator[epoch - start_idx] = d_running\n",
    "        \n",
    "        if epoch+1 - start_idx in save_epochs:\n",
    "            psnr, ssim = plot_generated_images(G, 3, epoch+1, device)\n",
    "            \n",
    "            file_path = './results/{}/generator_{}.pth'.format(experiment_name, epoch+1)\n",
    "            torch.save(G.state_dict(), file_path)\n",
    "            print(\"Epoch {}/{} Loss G: {}+{} Loss D: {} PSNR: {} SSIM: {}\".format(epoch+1, epochs, loss_g1, loss_g2, d_running, psnr, ssim))\n",
    "        else:\n",
    "            print(\"Epoch {}/{} Loss G: {} Loss D: {}\".format(epoch+1, epochs, g_running, d_running))\n",
    "            \n",
    "    file_path = './results/{}/generator.pth'.format(experiment_name)\n",
    "    torch.save(G.state_dict(), file_path)\n",
    "    file_path = './results/{}/discriminator.pth'.format(experiment_name)\n",
    "    torch.save(D.state_dict(), file_path)\n",
    "    return losses_generator, losses_discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288fa1e3-6274-4ad5-9b89-ace24b1df776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(G, n_imgs, epoch, device, val_ds=val_ds):\n",
    "    G.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        fig, axs = plt.subplots(n_imgs, 3, figsize=(15, 5 * n_imgs))\n",
    "        psnr = 0\n",
    "        ssim = 0\n",
    "        for i, (lr_img, hr_img) in enumerate(val_ds):\n",
    "            if i >= n_imgs:\n",
    "                break\n",
    "\n",
    "            lr_img = lr_img.to(device).unsqueeze(0)\n",
    "            hr_img = hr_img.to(device).unsqueeze(0)\n",
    "\n",
    "            # Generate super-resolved image\n",
    "            sr_img = G(lr_img)\n",
    "\n",
    "            psnr_value = torchmetrics.functional.image.peak_signal_noise_ratio(sr_img, hr_img).item()\n",
    "            ssim_value = torchmetrics.functional.image.structural_similarity_index_measure(sr_img, hr_img).item() \n",
    "            psnr += psnr_value\n",
    "            ssim += ssim_value\n",
    "            # Move images to CPU for plotting\n",
    "            lr_img = lr_img.cpu().squeeze(0).permute(1, 2, 0)\n",
    "            hr_img = hr_img.cpu().squeeze(0).permute(1, 2, 0)\n",
    "            sr_img = sr_img.cpu().squeeze(0).permute(1, 2, 0)\n",
    "\n",
    "            # Plotting\n",
    "            axs[i, 0].imshow(lr_img)\n",
    "            axs[i, 0].set_title('Low-Resolution')\n",
    "            axs[i, 0].axis('off')\n",
    "            axs[i, 1].imshow(hr_img)\n",
    "            axs[i, 1].set_title('High-Resolution')\n",
    "            axs[i, 1].axis('off')\n",
    "            axs[i, 2].imshow(sr_img)\n",
    "            axs[i, 2].set_title('Super-Resolved')\n",
    "            axs[i, 2].axis('off')\n",
    "\n",
    "            axs[i, 2].text(0.5, -0.1, f'SSIM: {ssim_value:.4f}\\nPSNR: {psnr_value:.2f} dB', horizontalalignment='center', verticalalignment='bottom', transform=axs[i, 2].transAxes, color='black')\n",
    "        psnr /= n_imgs\n",
    "        ssim /= n_imgs\n",
    "\n",
    "    # Save the plot\n",
    "    # axs[-1, 1].text(0.5, -0.1, f'Overall \\nSSIM: {ssim:.4f}\\nPSNR: {psnr:.2f} dB', horizontalalignment='center', verticalalignment='bottom', transform=axs[-1, 1].transAxes color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/{experiment_name}/G_{epoch}.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    # print(f\"{epoch} \\t PSNR: {psnr:.2f} \\t SSIM:{ssim:.4f}\")\n",
    "\n",
    "    # Set model back to training mode\n",
    "    G.train()\n",
    "    return psnr, ssim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f85c0-878a-49f9-819d-f0a5c2e2e8ee",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2741f-0e2c-4630-a072-de97f367fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(g, test_dl):\n",
    "    g = g.eval()\n",
    "    device = next(g.parameters()).device\n",
    "    ssim = 0\n",
    "    psnr = 0\n",
    "    for lr, hr in test_dl:\n",
    "        lr = lr.to(device)\n",
    "        hr_img = hr.to(device)\n",
    "\n",
    "        sr_img = g(lr)\n",
    "        psnr += torchmetrics.functional.image.peak_signal_noise_ratio(sr_img, hr_img).item()\n",
    "        ssim += torchmetrics.functional.image.structural_similarity_index_measure(sr_img, hr_img).item()\n",
    "\n",
    "    psnr /= len(test_dl)\n",
    "    ssim /= len(test_dl)\n",
    "    g = g.train()\n",
    "    return psnr, ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3862c-9b7f-4a68-9891-415fdecf07db",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2b888-918b-4066-b9f1-f1e4ab9ff267",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Generator().to('cuda')\n",
    "d = Discriminator().to('cuda')\n",
    "\n",
    "optimizerD = torch.optim.Adam(d.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "optimizerG = torch.optim.Adam(g.parameters(), lr=0.0020, betas=(0.5, 0.999))\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62503b4a-b656-44a5-9881-2aab83119de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "\n",
    "print(\"DISCRIMINATOR\")\n",
    "# torchsummary.summary(d, (3, 256, 256))\n",
    "print()\n",
    "print(\"GENERATOR\")\n",
    "# torchsummary.summary(g, (3, 64, 64))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44cf2d-d4f7-4065-a5ed-fe64d377ce79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_loss, d_loss = train(g, d, train_dl, criterion, g_criterion, optimizerD, optimizerG, 200, save_epochs = [1, 10, 20, 40, 50, 70, 80, 100, 150, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b335772-892b-4ab7-8313-f54d35cc7279",
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr, ssim = evaluate(g, val_dl)\n",
    "\n",
    "print(f\"PSNR: {psnr:.2f} dB, SSIM: {ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d99f86-568e-4bff-a8e4-f034bbcc1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(g_loss, label='Generator Loss')\n",
    "plt.plot(d_loss, label='Discriminator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('GAN Training Loss')\n",
    "plt.legend()\n",
    "plt.savefig('losses.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5cca0-c75d-4562-bf6b-0d60a9f7e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss, d_loss = train(g, d, train_dl, criterion, g_criterion, optimizerD, optimizerG, 200, save_epochs = [1, 10, 50, 100, 150, 200], start_idx=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be14c9b8-7f1b-4bc2-9523-9b70ddf7c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss += g_loss_\n",
    "d_loss += d_loss_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(g_loss, label='Generator Loss')\n",
    "plt.plot(d_loss, label='Discriminator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('GAN Training Loss')\n",
    "plt.legend()\n",
    "plt.savefig('losses.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646c726-4fd4-4f7f-b5f9-272d868345fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr, ssim = evaluate(g, val_dl)\n",
    "\n",
    "print(f\"PSNR: {psnr:.2f} dB, SSIM: {ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3066f6d4-9deb-429b-98af-6413ebd3ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_eval = g.load_state_dict(torch.load(f\"./results/{experiment_name}/generator.pth\"))\n",
    "# g.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
